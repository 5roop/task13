{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"006_crawling_juznevesti.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upoznatom\t21.187\t21.827\n",
      "meselu\t21.847\t22.427\n",
      "ljudskoj\t22.467\t22.848\n",
      "izvanrednoj\t22.888\t23.528\n",
      "deceni\t23.568\t24.588\n",
      "i\t24.608\t24.668\n",
      "saia\t24.728\t25.128\n",
      "berlin\t25.168\t25.549\n",
      "je\t25.589\t25.649\n",
      "tcvridio\t25.729\t26.649\n",
      "da\t26.689\t26.809\n",
      "bi\t26.889\t27.309\n",
      "citiram\t27.369\t28.149\n",
      "teško\t28.209\t28.630\n",
      "bilo\t28.710\t29.050\n",
      "u\t29.070\t29.150\n",
      "ljusi\t29.190\t29.610\n",
      "19.\t29.930\t30.270\n",
      "vijeka\t30.310\t31.050\n",
      "pronaći\t31.090\t31.851\n",
      "jednu\t31.911\t32.231\n",
      "jedinu\t32.331\t32.751\n",
      "političku\t32.831\t33.391\n",
      "i\t33.431\t33.491\n",
      "društvenu\t33.531\t34.031\n",
      "ideju\t34.071\t34.832\n",
      "nastalu\t34.872\t35.552\n",
      "na\t35.592\t35.692\n",
      "domaćem\t35.752\t36.272\n",
      "tlu\t36.332\t37.713\n",
      "zavješen\t38.173\t38.633\n",
      "citat\t38.693\t39.433\n",
      "te\t39.473\t39.593\n",
      "da\t39.613\t39.733\n",
      "se\t39.793\t39.893\n",
      "sa\t40.433\t40.674\n",
      "eventualnim\t40.714\t41.514\n",
      "izuzetkom\t41.554\t42.254\n",
      "postojevih\t42.314\t43.094\n",
      "ideja\t43.134\t43.615\n",
      "o\t43.655\t44.115\n",
      "nepružanju\t44.135\t44.915\n",
      "otporja\t44.975\t46.255\n",
      "sve\t46.315\t46.536\n",
      "ideje\t46.576\t46.896\n",
      "koje\t46.956\t47.136\n",
      "nalazimo\t47.176\t47.736\n",
      "ne\t47.796\t47.916\n",
      "samo\t47.996\t48.256\n",
      "što\t48.296\t48.416\n",
      "su\t48.496\t48.616\n",
      "izrasile\t48.656\t49.296\n",
      "iz\t49.336\t49.697\n",
      "nekog\t49.737\t50.057\n",
      "dalekog\t50.097\t50.597\n",
      "zapadnjačkog\t50.637\t51.377\n",
      "koljena\t51.437\t52.237\n",
      "nego\t52.277\t52.497\n",
      "pripadaju\t52.558\t53.258\n",
      "učenjima\t53.298\t54.478\n",
      "koja\t54.538\t54.798\n",
      "su\t54.878\t54.998\n",
      "postojala\t55.078\t55.719\n",
      "na\t55.759\t55.839\n",
      "zapadu\t55.919\t56.439\n",
      "10\t56.739\t56.959\n",
      "ili\t56.999\t57.139\n",
      "20\t57.239\t57.739\n",
      "g\t57.779\t58.199\n",
      "prije\t58.239\t58.419\n",
      "nego\t58.479\t58.660\n",
      "što\t58.700\t58.840\n",
      "su\t58.920\t59.000\n",
      "se\t59.040\t59.160\n",
      "pi\t59.220\t59.540\n",
      "put\t59.640\t59.840\n"
     ]
    }
   ],
   "source": [
    "model_name = \"classla/wav2vec2-large-slavic-parlaspeech-hr\"\n",
    "\n",
    "\n",
    "from itertools import groupby\n",
    "import torch\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2CTCTokenizer\n",
    "import soundfile as sf\n",
    "\n",
    "##############\n",
    "# load model & audio and run audio through model\n",
    "##############\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\n",
    "    model_name, unk_token=\"[UNK]\", \n",
    "    # pad_token=\"[PAD]\", \n",
    "    # word_delimiter_token=\"|\"\n",
    "    )\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(\n",
    "    feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
    "\n",
    "processor = Wav2Vec2Processor(\n",
    "    feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name).cuda()\n",
    "\n",
    "\n",
    "audio_filepath = \"audio_2.wav\"\n",
    "speech, sample_rate = sf.read(audio_filepath)\n",
    "input_values = processor(speech[0:60*sample_rate], sampling_rate=sample_rate, return_tensors=\"pt\").input_values.cuda()\n",
    "\n",
    "logits = model(input_values).logits\n",
    "\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.decode(predicted_ids[0]).lower()\n",
    "\n",
    "##############\n",
    "# this is where the logic starts to get the start and end timestamp for each word\n",
    "##############\n",
    "words = [w for w in transcription.split() if len(w) > 0]\n",
    "predicted_ids = predicted_ids[0].tolist()\n",
    "duration_sec = input_values.shape[1] / sample_rate\n",
    "\n",
    "\n",
    "ids_w_time = [(i / len(predicted_ids) * duration_sec, _id) for i, _id in enumerate(predicted_ids) if _id != processor.tokenizer.pad_token_id]\n",
    "times_and_tokens = [(i, processor.tokenizer.convert_ids_to_tokens(j) )for i, j in ids_w_time]\n",
    "indices_to_pop = list()\n",
    "for i, tt in enumerate(times_and_tokens):\n",
    "    try:\n",
    "        if tt[1] == times_and_tokens[i+1][1]:\n",
    "            indices_to_pop.append(i)\n",
    "    except IndexError:\n",
    "        continue\n",
    "for i in sorted(indices_to_pop)[::-1]:\n",
    "    times_and_tokens.pop(i)\n",
    "word_starts = []\n",
    "word_ends = []\n",
    "word_started = True\n",
    "for i, (time, token) in enumerate(times_and_tokens):\n",
    "    if word_started:\n",
    "        word_starts.append(time)\n",
    "        word_started = False\n",
    "    if token == \" \":\n",
    "        word_ends.append(time)\n",
    "        word_started = True\n",
    "    if i == len(times_and_tokens) -1:\n",
    "        word_ends.append(time)\n",
    "for word, start, end in zip(words, word_starts, word_ends):\n",
    "    print(word, f\"{start:0.3f}\", f\"{end:0.3f}\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[76, 76, 76]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(len, (words, word_starts, word_ends)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f6f5766036ee03d059e365a942add07f79c17033585e9357ee8157d52fe6bb9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
