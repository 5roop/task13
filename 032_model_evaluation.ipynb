{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|     |      dev |     test |\n",
      "|:----|---------:|---------:|\n",
      "| WER | 0.295206 | 0.290094 |\n",
      "| CER | 0.140766 | 0.137642 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_metric\n",
    "df = pd.read_json(\"30_dev_and_test_split_transcriptions_for_inspection.jsonl\", lines=True)\n",
    "wer = load_metric(\"wer\")\n",
    "cer = load_metric(\"cer\")\n",
    "\n",
    "r = dict()\n",
    "for split in \"dev test\".split():\n",
    "    subset = df[df.split == split]\n",
    "    gold = subset.preprocessed_original_text.tolist()\n",
    "    transcriptions = subset.model_output.tolist()\n",
    "    w = wer.compute(predictions = transcriptions,\n",
    "            references = gold)\n",
    "    c = cer.compute(predictions = transcriptions,\n",
    "            references = gold)\n",
    "    r[split] = {\"WER\": w, \"CER\": c}\n",
    "    \n",
    "print(pd.DataFrame(r).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "--2022-08-18 12:33:02--  https://huggingface.co/classla/wav2vec2-xls-r-parlaspeech-hr/raw/main/00020570a.flac.wav\n",
      "Resolving www-proxy.ijs.si (www-proxy.ijs.si)... 2001:1470:ff80::3128:1, 193.2.4.4\n",
      "Connecting to www-proxy.ijs.si (www-proxy.ijs.si)|2001:1470:ff80::3128:1|:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 170412 (166K) [audio/wave]\n",
      "Saving to: ‘00020570a.flac.wav’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 30%  230K 1s\n",
      "    50K .......... .......... .......... .......... .......... 60%  458K 0s\n",
      "   100K .......... .......... .......... .......... .......... 90% 34.1M 0s\n",
      "   150K .......... ......                                     100%  126M=0.3s\n",
      "\n",
      "2022-08-18 12:33:03 (508 KB/s) - ‘00020570a.flac.wav’ saved [170412/170412]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ve[PAD]l[PAD]i[PAD]k[PAD] [PAD]b[PAD]ro[PAD]j[PAD] [PAD]p[PAD]o[PAD]s[PAD]lo[PAD]v[PAD]nih [PAD]s[PAD]u[PAD]b[PAD]je[PAD]k[PAD]a[PAD]t[PAD]a[PAD] [PAD]p[PAD]o[PAD]s[PAD]lu[PAD]je[PAD] [PAD]s[PAD]a[PAD] [PAD]m[PAD]i[PAD]n[PAD]o[PAD]s[PAD]o[PAD]m[PAD] [PAD]v[PAD]e[PAD]l[PAD]i[PAD]k[PAD] [PAD]d[PAD]e[PAD]o[PAD]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, Wav2Vec2FeatureExtractor, Wav2Vec2Processor,Wav2Vec2CTCTokenizer\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load model and tokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(\n",
    "    \"./\",\n",
    "    #unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\" \"\n",
    "    )\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(\n",
    "    feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
    "\n",
    "processor = Wav2Vec2Processor(\n",
    "    feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"model_01_preprocessed/checkpoint-2440/\")\n",
    "\n",
    "\n",
    "# download the example wav files:\n",
    "os.system(\"wget https://huggingface.co/classla/wav2vec2-xls-r-parlaspeech-hr/raw/main/00020570a.flac.wav\")\n",
    "\n",
    "# read the wav file \n",
    "speech, sample_rate = sf.read(\"00020570a.flac.wav\")\n",
    "input_values = processor(speech, sampling_rate=sample_rate, return_tensors=\"pt\").input_values.to(device)\n",
    "\n",
    "# remove the raw wav file\n",
    "os.system(\"rm 00020570a.flac.wav\")\n",
    "\n",
    "# retrieve logits\n",
    "logits = model.to(device)(input_values).logits\n",
    "\n",
    "# take argmax and decode\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcc056fad38442385dad404ad5bf2c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/214 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283d27d196c542688e0ff386ad2565a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/121 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfeb4bcf89af4a49a6386a169bc104c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32db0b0851a942b88fc8b55e490ba324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149c7b2d459e47caa84dc75abb7e5ea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2022-08-18 12:47:33--  https://huggingface.co/classla/wav2vec2-xls-r-parlaspeech-hr/raw/main/00020570a.flac.wav\n",
      "Resolving www-proxy.ijs.si (www-proxy.ijs.si)... 2001:1470:ff80::3128:1, 193.2.4.4\n",
      "Connecting to www-proxy.ijs.si (www-proxy.ijs.si)|2001:1470:ff80::3128:1|:8080... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 170412 (166K) [audio/wave]\n",
      "Saving to: ‘00020570a.flac.wav’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 30%  230K 1s\n",
      "    50K .......... .......... .......... .......... .......... 60%  457K 0s\n",
      "   100K .......... .......... .......... .......... .......... 90% 42.7M 0s\n",
      "   150K .......... ......                                     100% 50.2M=0.3s\n",
      "\n",
      "2022-08-18 12:47:33 (508 KB/s) - ‘00020570a.flac.wav’ saved [170412/170412]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'velik broj poslovnih subjekata posluje sa minosom velik deo'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import soundfile as sf\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# load model and tokenizer\n",
    "processor = Wav2Vec2Processor.from_pretrained(\n",
    "    \"5roop/wav2vec2-xls-r-juznevesti-sr\")\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"5roop/wav2vec2-xls-r-juznevesti-sr\")\n",
    "\n",
    "\n",
    "# download the example wav files:\n",
    "os.system(\"wget https://huggingface.co/classla/wav2vec2-xls-r-parlaspeech-hr/raw/main/00020570a.flac.wav\")\n",
    "\n",
    "# read the wav file \n",
    "speech, sample_rate = sf.read(\"00020570a.flac.wav\")\n",
    "input_values = processor(speech, sampling_rate=sample_rate, return_tensors=\"pt\").input_values.to(device)\n",
    "\n",
    "# remove the raw wav file\n",
    "os.system(\"rm 00020570a.flac.wav\")\n",
    "\n",
    "# retrieve logits\n",
    "logits = model.to(device)(input_values).logits\n",
    "\n",
    "# take argmax and decode\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "transcription = processor.decode(predicted_ids[0])\n",
    "\n",
    "transcription # 'velik broj poslovnih subjekata posluje sa minosom velik deo'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f6f5766036ee03d059e365a942add07f79c17033585e9357ee8157d52fe6bb9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
